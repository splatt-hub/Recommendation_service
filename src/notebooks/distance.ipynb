{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открой файл [distances.ipynb](src/notebooks/distances.ipynb). \n",
    "* Объедини общие данные о фильмах [tmdb_5000_movies](https://files.sberdisk.ru/s/te4QbzdxKgsFQXA) и каст фильмов \n",
    "[tmdb_5000_credits](https://files.sberdisk.ru/s/H9oRuXQt5mFz3T9). \n",
    "* Оставь в датасете только фильмы, которые вышли в \"релиз\".\n",
    "* Убери фильмы с пропусками в колонках ['overview', 'genres', 'keywords']\n",
    "* Выведи количество фильмов, оставшихся в выборке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4792"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c = pd.read_csv('../../datasets/tmdb_5000_credits.csv')\n",
    "df_m = pd.read_csv('../../datasets/tmdb_5000_movies.csv')\n",
    "\n",
    "new_df = pd.merge(df_m, df_c, left_on = 'id', right_on = 'movie_id') #объединение df\n",
    "new_df.rename(columns={'title_x': 'title'}, inplace=True) #переименов слотбец title\n",
    "new_df.drop('title_y', axis=1, inplace=True) #удаляем повторную колону названий\n",
    "new_df = new_df[new_df['status'] == 'Released'] #фильтрация данных по Released\n",
    "new_df.dropna(subset=['overview', 'genres', 'keywords'], inplace=True) #убираем фильмы с пропускаи в колонках\n",
    "new_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритм рекомендации на основе описания фильма (`overview`) и ключевых слов к фильму (`keywords`). \n",
    "Объедини тексты этих колонок и проведи предобработку:\n",
    "* Замени NaN в описании фильма на пустой символ `''`\n",
    "* Удали все английские стоп-слова (используй параметр `stop_words` в `TfidfVectorizer`)\n",
    "* Рассчитай матрицу [Tf-Idf](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) для описания фильмов.\n",
    "\n",
    "Выведи размер получившейся матрицы\n",
    "> Параметр `max_features` в `TfidfVectorizer` должен быть равен 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4792, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "new_df['recomend'] = new_df['overview']+ ' ' + new_df['keywords'] #объединяем текст колонок\n",
    "vector=TfidfVectorizer(max_features=10000, stop_words='english') #удаляем все англ стоп-слова\n",
    "new_df['recomend'] = new_df['recomend'] .fillna('') #заменяем NaN пустой символ\n",
    "matrix = vector.fit_transform(new_df['recomend'] ) #создаем матрицу\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитай [cosine similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) \n",
    "между фильмами. Составь из этой матрицы `pd.DataFrame`. Для дальнейшего удобства, \n",
    "колонки и индексы таблицы назови согласно`id` фильма. \\\n",
    "Сохрани получившийся `DataFrame` c расстояниями в папку [assets](src/assets) с названием `distance.csv`.\n",
    "А сам объединенный датасет с фильмами сохрани в папку [assets](src/assets) с названием `movies.csv`.\n",
    "\n",
    "> Получившиеся файлы `distance.csv` и `movies.csv` пушить в GitLab не нужно!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(matrix) #применение cosine similarity \n",
    "distance = pd.DataFrame(cosine_sim, index=new_df['movie_id'], columns = new_df['movie_id']) #колонки и индексы названы согласно id фильма\n",
    "\n",
    "#Сохранение датафреймов\n",
    "distance.to_csv('../../src/assets/distance.csv')\n",
    "new_df.to_csv('../../src/assets/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
